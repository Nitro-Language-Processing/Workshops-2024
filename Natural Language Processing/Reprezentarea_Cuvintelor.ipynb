{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reprezentarea Cuvintelor (sau _Word Embeddings_)\n",
    "\n",
    "Acest laborator prezintă conceptele cheie și pașii pentru implementarea unei modalități de reprezentare a textelor sau cuvintelor ca vectori."
   ],
   "metadata": {
    "id": "q_G6xYEW1Eja"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setul de date"
   ],
   "metadata": {
    "id": "xnF1IrxEd43O"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Primul set de date pe care îl vom folosi este _common_texts_. Acesta conține o listă de documente, unde fiecare document conține o serie de cuvinte cheie prezentate tot ca o listă. Setul este mic si multe cuvinte se repetă, ceea ce îl face ușor de urmărit:"
   ],
   "metadata": {
    "id": "Gti7OAr-dmW-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from gensim.test.utils import common_texts\n",
    "\n",
    "common_texts"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4UJhYwhZ8vL",
    "outputId": "c5c7626b-12cd-4eed-9681-ad4b7f952a18"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text = [\n",
    "  'human interface computer',\n",
    "  'survey user computer system response time',\n",
    "  'eps user interface system',\n",
    "  'system human system eps',\n",
    "  'user response time',\n",
    "  'trees',\n",
    "  'graph trees',\n",
    "  'graph minors trees',\n",
    "  'graph minors survey'\n",
    "]"
   ],
   "metadata": {
    "id": "Y5HHDl5WDkOy"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "În general o să folosim seturi de date mai mari, care ne transmit mai multe informații. Momentan folosim acest set de date fiindcă se mișcă mai rapid."
   ],
   "metadata": {
    "id": "pTqWJZnvAKOU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bag of Words\n",
    "\n",
    "Nu vom implementa niciun model manual, vom folosi implementările deja existente. Pentru Bag of Words, aceasta se numește _CountVectorizer_:"
   ],
   "metadata": {
    "id": "kGGceCGWaRcM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "metadata": {
    "id": "sddR0EQSBSot"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "_CountVectorizer_ este clasa pe care o vom folosi pentru a traduce fiecare propoziție din setul de date în varianta numerică a acesteia. Pentru asta trebuie să creăm o instanță a clasei noastre:"
   ],
   "metadata": {
    "id": "VC4FZiO0BS0C"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "vectorizer = CountVectorizer()"
   ],
   "metadata": {
    "id": "R0g_8f2rB0L-"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "_vectorizer_ este numele pe care îl vom da listei noastre de valori care ne transmit informațiile despre text.\n",
    "Pentru a aplica modelul pe textul nostru trebuie să apelăm funcția _fit_transform_ din interiorul instanței:"
   ],
   "metadata": {
    "id": "uGTP4eJdB0Ya"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X = vectorizer.fit_transform(text)"
   ],
   "metadata": {
    "id": "bP1R_KMoCi2g"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funcția aplicată mai sus extrage lista de cuvinte din text și calculează de câte ori apare fiecare cuvânt în fiecare propoziție. Putem vedea lista de cuvinte folosind altă funcție din instanță:"
   ],
   "metadata": {
    "id": "do2dfaBtFV0o"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "vectorizer.get_feature_names_out()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADV-Mh37E9DF",
    "outputId": "04c5c669-0a81-4721-ac56-2a1ff7d7621a"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['computer', 'eps', 'graph', 'human', 'interface', 'minors',\n",
       "       'response', 'survey', 'system', 'time', 'trees', 'user'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "X este lista noastră de valori. Fiecare linie reprezintă o propoziție, fiecare coloană reprezintă un cuvânt, iar valorile aflate la intersecție ne spun de câte ori apare fiecare cuvânt în fiecare propoziție."
   ],
   "metadata": {
    "id": "YoLQlpAkCjCU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X.toarray()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbtXiGHUEqJC",
    "outputId": "ac946455-c4b1-41cb-d02c-ba884ed30930"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gata! Acum știm vectorizarea fiecărei propoziții folosind Bag of Words!"
   ],
   "metadata": {
    "id": "8-D0Tn4DFzmC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EXERCIȚIU:\n",
    "\n"
   ],
   "metadata": {
    "id": "9_roanSbF6rO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La fel ca majoritatea claselor, CountVectorizer are o serie de parametri\n",
    "\n",
    "\n",
    " cu valori predefinite. Printre acestea se numără și _binary=False_, care numără de câte ori apar cuvintele. Setează valoarea acestui parametru ca _True_, antrenează din nou pe textul dat și afișează noua listă de valori (X)."
   ],
   "metadata": {
    "id": "9-i_TTioGIRF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: creează o instanță cu parametrul binary setat True\n",
    "\n",
    "# TODO: antrenează din nou pe text\n",
    "\n",
    "# TODO: afișează noua listă de valori (X)\n"
   ],
   "metadata": {
    "id": "4ylruyKlGGmP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5409e802-2d62-4446-bc92-fcb599de1410",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TFIDF\n",
    "\n",
    "TFIDF este antrenat și apelat exact la fel ca Bag of Words, doar că funcția pe care o folosim se numește _TfidfVectorizer_. Creează lista de valori numerice corespunzătoare textului folosind metoda TFIDF din cadrul clasei de mai jos:"
   ],
   "metadata": {
    "id": "SErBvUe7aP7v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TODO: La fel ca mai sus, creează o instanță a clasei TfidfVectorizer, antreneaz-o pe text și afișează lista de valori X\n",
    "\n",
    "# TODO: antrenează din nou pe text\n",
    "\n",
    "# TODO: afișează noua listă de valori (X)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7KNFe_r9aPTA",
    "outputId": "76dca847-0ae1-423c-8cbc-41309bc25aa4",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word2Vec\n",
    "\n",
    "Word2Vec funcționează puțin diferit. Îl vom antrena pe lista de cuvinte (în loc de propoziții) și îi spunem să ia în considerare cuvintele care apar minim o dată:"
   ],
   "metadata": {
    "id": "z2x8GG6haW7u"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "vectorizer = Word2Vec(common_texts, min_count=1).wv"
   ],
   "metadata": {
    "id": "lK8fWrimIjeh"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Putem vedea lista de cuvinte folosind următoarea funcție:"
   ],
   "metadata": {
    "id": "_862fHDlJ3bs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "vectorizer.key_to_index"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ay0NKjqaI6T9",
    "outputId": "5df0cc7a-0e22-4e06-db64-73b24481e0cd"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'system': 0,\n",
       " 'graph': 1,\n",
       " 'trees': 2,\n",
       " 'user': 3,\n",
       " 'minors': 4,\n",
       " 'eps': 5,\n",
       " 'time': 6,\n",
       " 'response': 7,\n",
       " 'survey': 8,\n",
       " 'computer': 9,\n",
       " 'interface': 10,\n",
       " 'human': 11}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Noua noastră instanță vine cu o serie de funcții noi pe care le putem descoperi. Folosește funcția _most_similar(word)_ pentru a vedea cuvintele care seamănă cel mai mult cu cuvântul _system_:"
   ],
   "metadata": {
    "id": "2JDO0s5iKMoE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: găsește cuvintele cele mai apropiate de \"system\"\n"
   ],
   "metadata": {
    "id": "KstuGaPeapWO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b1e02131-9d9e-430d-dc4d-6d292b4898ed",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Folosește funcția _similarity(word1, word2)_ pentru a vedea cât de apropiate sunt cuvintele _human_ și _computer_:"
   ],
   "metadata": {
    "id": "QiUhEidcK8Fs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: găsește similaritatea între \"human\" și \"computer\"\n"
   ],
   "metadata": {
    "id": "loQCmdJMap5S",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "893f29aa-f3ea-499d-b60f-d200e57f64c6",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ce se întâmplă dacă încercăm să calculăm _king + woman - man_ ?"
   ],
   "metadata": {
    "id": "R32-lcScLYcK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "vectorizer.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])"
   ],
   "metadata": {
    "id": "RYeUYNunax23",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "outputId": "cec5aa9f-1fa5-4621-cbc6-b5a7c040465a"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"Key 'king' not present in vocabulary\"",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-19-019e0603ca6e>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mvectorizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmost_similar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpositive\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"king\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"woman\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnegative\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"man\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36mmost_similar\u001B[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001B[0m\n\u001B[1;32m    839\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    840\u001B[0m         \u001B[0;31m# compute the weighted average of all keys\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 841\u001B[0;31m         \u001B[0mmean\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_mean_vector\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpre_normalize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpost_normalize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mignore_missing\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    842\u001B[0m         all_keys = [\n\u001B[1;32m    843\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mkeys\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_KEY_TYPES\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhas_index_for\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36mget_mean_vector\u001B[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001B[0m\n\u001B[1;32m    516\u001B[0m                 \u001B[0mtotal_weight\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mabs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    517\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mignore_missing\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 518\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Key '{key}' not present in vocabulary\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    519\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    520\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtotal_weight\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Key 'king' not present in vocabulary\""
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modelul nostru nu a învățat aceste cuvinte, așa că nu știe ce să facă cu ele. Încearcă să calculezi diferența între alte 3 cuvinte din lista de cuvinte știute:"
   ],
   "metadata": {
    "id": "1YwnAzxCLm10"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO\n"
   ],
   "metadata": {
    "id": "a3NITmGVa3rT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7c82f3be-6cdf-4539-d293-f56f946f914c",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BONUS"
   ],
   "metadata": {
    "id": "RSHYVd2chjjK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pentru următoarele exerciții vom folosi un set de date care conține 3.000.000 de cuvinte sub forma unei serii de știri extrase de pe Google. Întrucât setul este foarte mare și ar dura extrem de mult timp să îl antrenăm singuri, vom downloada modelul direct antrenat ca să ne uităm cum funcționează. Ne așteptăm ca downloadul să dureze minim 10 minute, deci aveți grijă când rulați această celulă:"
   ],
   "metadata": {
    "id": "MLOcFNf1ewu1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load(\"word2vec-google-news-300\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5LAkwBJafdl",
    "outputId": "4d5a8f51-1f41-42e4-b858-ef9980515e69"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.most_similar('system')"
   ],
   "metadata": {
    "id": "AEtcroBuTdzA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a0aa1b4d-360f-45dd-8924-fbf9e2be7bd4"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('systems', 0.7227916717529297),\n",
       " ('sytem', 0.7129376530647278),\n",
       " ('sys_tem', 0.5871982574462891),\n",
       " ('System', 0.5275423526763916),\n",
       " ('mechanism', 0.5058810114860535),\n",
       " ('sysem', 0.5027822852134705),\n",
       " ('systen', 0.49969804286956787),\n",
       " ('system.The', 0.49599188566207886),\n",
       " ('sytems', 0.4949610233306885),\n",
       " ('computerized', 0.47604817152023315)]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.similarity('human', 'computer')"
   ],
   "metadata": {
    "id": "bV4_PiS-UANM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d26de90b-47fc-49ff-b947-e8aa3ff38310"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.18846479"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])"
   ],
   "metadata": {
    "id": "vf3ihweJUGh7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a769604f-34d7-44e1-d2ab-d41d7a7fb909"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321839332581),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.most_similar(positive=['human'], negative=['computer', 'time'])"
   ],
   "metadata": {
    "id": "-FucrYuOUQVO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dfba8e2d-ac6f-425c-edce-768fb57bb0af"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('non_toxigenic_C.', 0.3579254448413849),\n",
       " ('allotransplantation', 0.3464714586734772),\n",
       " ('speciesism', 0.3178519308567047),\n",
       " ('Atlantic_salmon_Salmo', 0.29254624247550964),\n",
       " ('nonhuman_animals', 0.2893490791320801),\n",
       " ('Sus_scrofa', 0.28739631175994873),\n",
       " ('K.Kahne_###-###', 0.2862851619720459),\n",
       " ('Neurotrophic_Factor', 0.2850346565246582),\n",
       " ('palmitoleic_acid', 0.28359511494636536),\n",
       " ('unbridled_individualism', 0.2827090919017792)]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vom instala modulul _wikipedia_ pentru a putea accesa paginile direct din cod:"
   ],
   "metadata": {
    "id": "mM-LSfLZMYPy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install wikipedia"
   ],
   "metadata": {
    "id": "ClB4fP-bniCy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "df428dd3-9b81-4d93-d6cd-040e06e2d215"
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=9f750bcf936db970e0f2f06fd203378246c04e12d47bd617799022094f2b9912\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Descarcă un articol de pe wikipedia. Înlocuiește _page\\_title_ cu un titlu de pagină de pe wikipedia:"
   ],
   "metadata": {
    "id": "ZPnKnhbchtLQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import wikipedia\n",
    "\n",
    "page_title = \"\" # TODO: Alege un titlu de pe wikipedia\n",
    "page = wikipedia.page(page_title, auto_suggest=False)\n",
    "\n",
    "print(page.content)"
   ],
   "metadata": {
    "id": "FM3ziGq8hxA2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1d1b3481-42aa-485f-c986-3f1ba8136d97"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Descoperă câte cuvinte de pe pagina de wikipedia apar în modelul tău și câte nu."
   ],
   "metadata": {
    "id": "ETw3pflZNH5a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "id": "jJDGt_4pWIOi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "43c4c840-e246-4dc5-df8c-3535534c4cf3"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Cate cuvinte de pe pagina de wiki apar în model și câte nu?\n",
    "from nltk import word_tokenize\n",
    "\n",
    "words = list(set(word_tokenize(page.content.lower())))\n",
    "words[:10]"
   ],
   "metadata": {
    "id": "hMH6kzu8NSs6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ff64f382-e0a2-48f7-d3ea-48443e71bad3"
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['eleanor',\n",
       " 'banas',\n",
       " 'considerable',\n",
       " 'forester',\n",
       " 'impulses',\n",
       " 'snow',\n",
       " 'whom',\n",
       " 'archetype',\n",
       " 'andalusia',\n",
       " 'uses']"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "lista_cuvinte = list(model.key_to_index.keys())\n",
    "lista_cuvinte[:10]"
   ],
   "metadata": {
    "id": "tRJWtH_oZbb4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d7003f5c-625b-49b0-8cd3-08d1fa33c1f6"
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said']"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Determină similaritatea între toate cuvintele de pe pagina de wiki. Afișează top 3 cele mai apropiate perechi de cuvinte și top 3 cele mai diferite."
   ],
   "metadata": {
    "id": "HCsC5DckNfA4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Determină similaritatea între toate cuvintele din textul de pe wiki\n",
    "\n",
    "# TODO: Afișează cele mai apropiate 3 perechi de cuvinte din text\n",
    "\n",
    "# TODO: Afișează cele mai diferite 3 perechi de cuvinte din text\n"
   ],
   "metadata": {
    "id": "9CirEW9vN2BB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8e1be9e0-dcd3-4ee3-a1a7-60c89f28645d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Pentru următoarele cuvinte: _user_, _survey_, _system_, _computer_ determină cel mai apropiat cuvânt folosind modelul încărcat pentru exercițiul bonus și modelul antrenat la începutul laboratorului. Observi diferențele?"
   ],
   "metadata": {
    "id": "9yT2NJk-N0Yw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Cel mai apropiat cuvânt de \"user\" folosind cele 2 modele\n",
    "\n",
    "# TODO: Cel mai apropiat cuvânt de \"survey\" folosind cele 2 modele\n",
    "\n",
    "# TODO: Cel mai apropiat cuvânt de \"system\" folosind cele 2 modele\n",
    "\n",
    "# TODO: Cel mai apropiat cuvânt de \"computer\" folosind cele 2 modele\n"
   ],
   "metadata": {
    "id": "4I-swOk3PMqA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3397a2c5-5302-4666-e3ea-f616e643375a"
   },
   "execution_count": 68,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Modelul antrenat de noi | Model preantrenat\n",
      "('eps', 0.13147011399269104) ('users', 0.7195653319358826)\n",
      "('trees', 0.19912061095237732) ('surveys', 0.8096452355384827)\n",
      "('computer', 0.21617141366004944) ('systems', 0.7227916717529297)\n",
      "('system', 0.21617139875888824) ('computers', 0.7979379892349243)\n"
     ]
    }
   ]
  }
 ]
}
